{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b65cc00a",
   "metadata": {},
   "source": [
    "# Module E: AI Applications - Individual Open Project\n",
    "## Content Recommendation System\n",
    "\n",
    "**Student Name:** Neelay Upadhyay  \n",
    "**Student ID:** iitrpr_ai_25010718  \n",
    "**Submission Date:** 17.01.26\n",
    "\n",
    "---\n",
    "\n",
    "### Problem Definition & Objective\n",
    "\n",
    "#### Selected Project Track\n",
    "**Personalization & Recommender Systems**\n",
    "\n",
    "#### Problem Statement\n",
    "Users face decision fatigue when navigating vast content libraries on digital platforms. This project builds an intelligent recommendation engine that analyzes user behavior to deliver personalized content suggestions, reducing discovery time and improving engagement.\n",
    "\n",
    "#### Real-world Relevance\n",
    "Recommender systems drive critical business metrics across platforms. Netflix saves $1 billion annually through reduced churn, while Amazon attributes 35% of revenue to recommendations. With 71% of consumers expecting personalized experiences, effective recommendation systems directly impact user retention and platform competitiveness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f6b24d",
   "metadata": {},
   "source": [
    "### Data Understanding & Preparation\n",
    "\n",
    "#### Dataset Source\n",
    "This project uses two datasets publicly available on Kaggle:<br>\n",
    "\n",
    "    \"TMDB 5000 Movie Dataset\" from The Movie Database (TMDb)<br>\n",
    "    \"Steam Store Games (Clean dataset)\" from Nik Davis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def43df5",
   "metadata": {},
   "source": [
    "## Movies Dataset: Loading and Preprocessing\n",
    "\n",
    "This section loads the TMDB movie metadata from Kaggle, merges it with credits, and prepares a cleaned feature-rich dataset for the recommendation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6e529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 ‚Äì Imports and setup\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import os\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Ensure NLTK tokenizer is available\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54a96c7",
   "metadata": {},
   "source": [
    "### Helper functions for JSON parsing and text processing\n",
    "\n",
    "This cell defines utility functions to parse JSON-like fields, extract directors and top cast, and normalize multi-word tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a540313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 ‚Äì Helper functions\n",
    "\n",
    "def clean_json(obj):\n",
    "    \"\"\"Extract 'name' from JSON list strings.\"\"\"\n",
    "    try:\n",
    "        L = []\n",
    "        for i in ast.literal_eval(obj):\n",
    "            L.append(i['name'])\n",
    "        return L\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "def clean_json_top3(obj):\n",
    "    \"\"\"Extract top 3 names from JSON list strings.\"\"\"\n",
    "    try:\n",
    "        L = []\n",
    "        counter = 0\n",
    "        for i in ast.literal_eval(obj):\n",
    "            if counter != 3:\n",
    "                L.append(i['name'])\n",
    "                counter += 1\n",
    "            else:\n",
    "                break\n",
    "        return L\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "def fetch_director(obj):\n",
    "    \"\"\"Extract Director name from crew.\"\"\"\n",
    "    L = []\n",
    "    try:\n",
    "        for i in ast.literal_eval(obj):\n",
    "            if i['job'] == 'Director':\n",
    "                L.append(i['name'])\n",
    "                break\n",
    "        return L\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "def collapse(L):\n",
    "    \"\"\"Remove spaces: 'Sam Worthington' -> 'SamWorthington'.\"\"\"\n",
    "    L1 = []\n",
    "    for i in L:\n",
    "        L1.append(i.replace(\" \", \"\"))\n",
    "    return L1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ce56c5",
   "metadata": {},
   "source": [
    "### Loading raw CSVs and merging\n",
    "\n",
    "Here, the TMDB movies and credits CSV files are loaded from the `data/` folder and merged on the `title` column, keeping only relevant metadata fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a038269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw TMDB datasets...\n",
      "Merging datasets...\n",
      "Selecting relevant columns...\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 ‚Äì Load, merge, select, handle missing\n",
    "\n",
    "print(\"Loading raw TMDB datasets...\")\n",
    "try:\n",
    "    movies = pd.read_csv(os.path.join(DATA_DIR, 'tmdb_5000_movies.csv'))\n",
    "    credits = pd.read_csv(os.path.join(DATA_DIR, 'tmdb_5000_credits.csv'))\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Raw CSV files not found in 'data/' folder. Please download them from Kaggle.\")\n",
    "    raise\n",
    "\n",
    "print(\"Merging datasets...\")\n",
    "movies = movies.merge(credits, on='title')\n",
    "\n",
    "print(\"Selecting relevant columns...\")\n",
    "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords',\n",
    "                 'cast', 'crew', 'release_date', 'vote_average', 'vote_count']]\n",
    "\n",
    "movies.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1973e92",
   "metadata": {},
   "source": [
    "### Cleaning, preprocessing, and feature engineering\n",
    "\n",
    "This cell parses JSON-like fields, tokenizes the overview, collapses multi-word entries, and builds a unified `tags` feature for content-based similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d08c086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming JSON fields...\n",
      "Creating master tags...\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 ‚Äì Transform JSON fields and build tags\n",
    "\n",
    "print(\"Transforming JSON fields...\")\n",
    "movies['genres'] = movies['genres'].apply(clean_json)\n",
    "movies['keywords'] = movies['keywords'].apply(clean_json)\n",
    "movies['cast'] = movies['cast'].apply(clean_json_top3)\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)\n",
    "\n",
    "movies['overview'] = movies['overview'].apply(lambda x: x.split())\n",
    "\n",
    "movies['genres'] = movies['genres'].apply(collapse)\n",
    "movies['keywords'] = movies['keywords'].apply(collapse)\n",
    "movies['cast'] = movies['cast'].apply(collapse)\n",
    "movies['crew'] = movies['crew'].apply(collapse)\n",
    "\n",
    "print(\"Creating master tags...\")\n",
    "movies['tags'] = (\n",
    "    movies['overview']\n",
    "    + movies['genres']\n",
    "    + movies['keywords']\n",
    "    + movies['cast']\n",
    "    + movies['crew']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9363a775",
   "metadata": {},
   "source": [
    "### Final feature table and stemming\n",
    "\n",
    "A compact dataframe is created with `id`, `title`, `tags`, and metadata, then tags are lowercased and stemmed before saving to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81450937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Porter Stemmer...\n",
      "Success! Processed data saved to 'data\\movies.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upadh\\AppData\\Local\\Temp\\ipykernel_7472\\3579612171.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.rename(columns={'movie_id': 'id'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 ‚Äì Final dataframe, stemming, save\n",
    "\n",
    "new_df = movies[['movie_id', 'title', 'tags', 'release_date',\n",
    "                 'vote_average', 'vote_count']]\n",
    "\n",
    "new_df.loc[:, 'tags'] = new_df['tags'].apply(lambda x: \" \".join(x))\n",
    "new_df.loc[:, 'tags'] = new_df['tags'].apply(lambda x: x.lower())\n",
    "\n",
    "print(\"Applying Porter Stemmer...\")\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem(text):\n",
    "    y = []\n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "    return \" \".join(y)\n",
    "\n",
    "new_df.loc[:, 'tags'] = new_df['tags'].apply(stem)\n",
    "\n",
    "new_df.rename(columns={'movie_id': 'id'}, inplace=True)\n",
    "\n",
    "output_path = os.path.join(DATA_DIR, 'movies.csv')\n",
    "new_df.to_csv(output_path, index=False)\n",
    "print(f\"Success! Processed data saved to '{output_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083fce95",
   "metadata": {},
   "source": [
    "## Games Dataset: Loading and Preprocessing\n",
    "\n",
    "This section loads the Steam Store games data from Kaggle, merges multiple metadata files, and prepares a cleaned feature-rich dataset for the recommendation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce378de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 ‚Äì Imports and setup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "\n",
    "DATA_DIR = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94532b07",
   "metadata": {},
   "source": [
    "### Loading and merging Steam datasets\n",
    "\n",
    "The core Steam datasets (main, descriptions, media, and requirements) are loaded from the `data/` folder and merged on the application ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e818e5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Steam datasets...\n",
      "Merging datasets...\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 ‚Äì Load and merge raw Steam CSVs\n",
    "\n",
    "print(\"Loading Steam datasets...\")\n",
    "try:\n",
    "    df_main = pd.read_csv(os.path.join(DATA_DIR, 'steam.csv'))\n",
    "    df_desc = pd.read_csv(os.path.join(DATA_DIR, 'steam_description_data.csv'))\n",
    "    df_media = pd.read_csv(os.path.join(DATA_DIR, 'steam_media_data.csv'))\n",
    "    df_reqs = pd.read_csv(os.path.join(DATA_DIR, 'steam_requirements_data.csv'))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Missing file. {e}\")\n",
    "    print(\"Please ensure steam.csv, steam_description_data.csv, steam_media_data.csv, and steam_requirements_data.csv are in the 'data/' folder.\")\n",
    "    raise\n",
    "\n",
    "print(\"Merging datasets...\")\n",
    "df_desc.rename(columns={'steam_appid': 'appid'}, inplace=True)\n",
    "df_media.rename(columns={'steam_appid': 'appid'}, inplace=True)\n",
    "df_reqs.rename(columns={'steam_appid': 'appid'}, inplace=True)\n",
    "\n",
    "df = df_main.merge(df_desc, on='appid', how='left')\n",
    "df = df.merge(df_media, on='appid', how='left')\n",
    "df = df.merge(df_reqs, on='appid', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e15c55c",
   "metadata": {},
   "source": [
    "### Cleaning metadata and creating rating features\n",
    "\n",
    "This step standardizes column names, parses release dates, and derives vote-based popularity metrics used for filtering and ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "837c7bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and transforming...\n",
      "üìâ Filtered dataset from 27075 -> 6376 high-quality games.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 ‚Äì Rename, date processing, rating features, popularity filter\n",
    "\n",
    "print(\"Cleaning and transforming...\")\n",
    "\n",
    "df.rename(columns={\n",
    "    'appid': 'id',\n",
    "    'name': 'title',\n",
    "    'short_description': 'overview',\n",
    "    'header_image': 'poster',\n",
    "}, inplace=True)\n",
    "\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "df['year'] = df['release_date'].dt.year.fillna(0).astype(int)\n",
    "\n",
    "df['total_votes'] = df['positive_ratings'] + df['negative_ratings']\n",
    "df['vote_average'] = (df['positive_ratings'] / df['total_votes']) * 10\n",
    "df['vote_average'] = df['vote_average'].fillna(0).round(1)\n",
    "df.rename(columns={'total_votes': 'vote_count'}, inplace=True)\n",
    "\n",
    "initial_count = len(df)\n",
    "df = df[df['vote_count'] >= 200]\n",
    "print(f\"üìâ Filtered dataset from {initial_count} -> {len(df)} high-quality games.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc3159",
   "metadata": {},
   "source": [
    "### Tag construction and feature engineering\n",
    "\n",
    "Genres, categories, tags, descriptions, and developer names are combined into a single lowercase `tags` field to support content-based similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfb22028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 ‚Äì Tag construction and requirements\n",
    "\n",
    "def clean_tags(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    return text.replace(';', ' ')\n",
    "\n",
    "df['genres_str'] = df['genres'].apply(clean_tags)\n",
    "df['categories_str'] = df['categories'].apply(clean_tags)\n",
    "df['tags_str'] = df['steamspy_tags'].apply(clean_tags)\n",
    "df['developer'] = df['developer'].fillna('')\n",
    "\n",
    "df['tags'] = (\n",
    "    df['overview'].fillna('') + \" \" +\n",
    "    df['genres_str'] + \" \" +\n",
    "    df['categories_str'] + \" \" +\n",
    "    df['tags_str'] + \" \" +\n",
    "    df['developer']\n",
    ").str.lower()\n",
    "\n",
    "df['pc_requirements'] = df['minimum'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8429ff",
   "metadata": {},
   "source": [
    "### Final games table and export\n",
    "\n",
    "The final games dataframe keeps IDs, metadata, tags, and requirements, removes invalid rows, and saves the result to `games.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b38f505a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Saved clean dataset to: data\\games.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 ‚Äì Final games dataframe and save\n",
    "\n",
    "final_df = df[[\n",
    "    'id',\n",
    "    'title',\n",
    "    'overview',\n",
    "    'tags',\n",
    "    'poster',\n",
    "    'year',\n",
    "    'vote_average',\n",
    "    'vote_count',\n",
    "    'developer',\n",
    "    'publisher',\n",
    "    'genres',\n",
    "    'pc_requirements'\n",
    "]]\n",
    "\n",
    "final_df = final_df.dropna(subset=['title', 'overview'])\n",
    "\n",
    "output_path = os.path.join(DATA_DIR, 'games.csv')\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Success! Saved clean dataset to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03989034",
   "metadata": {},
   "source": [
    "## Model / System Design\n",
    "\n",
    "### AI Technique Used\n",
    "This project implements a **content-based filtering recommendation system** driven by **natural language processing (NLP)**.  \n",
    "- **Embeddings:** Uses `sentence-transformers` (specifically `all-MiniLM-L6-v2`) to convert text data (titles, overviews, genres) into dense vector representations.  \n",
    "\n",
    "- **Similarity search:** Utilizes **FAISS (Facebook AI Similarity Search)** for efficient nearest-neighbor search to find content with semantically similar vectors.\n",
    "\n",
    "### Architecture & Pipeline Explanation\n",
    "The system follows a modular design divided into three primary components:\n",
    "\n",
    "1. **`run.py` (application entry point)**  \n",
    "   - Initializes the Flask web server and configures it to run on host `0.0.0.0` and port `7860`, enabling cloud deployment (e.g., Hugging Face Spaces).\n",
    "\n",
    "2. **`routes.py` (API controller)**  \n",
    "   - Defines API endpoints (such as `/recommend`) that receive user requests, validate inputs, trigger the recommendation logic, and return JSON responses to the frontend.\n",
    "\n",
    "3. **`nlp_engine.py` (core recommendation engine)**  \n",
    "   - Loads and cleans the movie and game datasets.  \n",
    "   - Encodes combined text features into vector embeddings.  \n",
    "   - Builds a FAISS index for fast retrieval.  \n",
    "   - Runs semantic search to return the top‚Äëk most relevant items for a given query.\n",
    "\n",
    "### Justification of Design Choices\n",
    "- **Sentence Transformers:** Preferred over TF‚ÄëIDF because they capture semantic context, not just exact word overlap, which improves recommendation quality.  \n",
    "\n",
    "- **FAISS:** Chosen for scalability, since brute‚Äëforce cosine similarity over all items becomes slow as the catalog grows.\n",
    "\n",
    "- **Flask:** Used as a lightweight framework to expose the model as an HTTP API with minimal overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c2db77",
   "metadata": {},
   "source": [
    "## Core Implementation\n",
    "\n",
    "This section implements the content-based recommendation engine using Sentence Transformers for embeddings and FAISS for similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7968bd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\upadh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Core recommendation engine: NeuroBrain (Tailored version for notebook)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "\n",
    "_shared_model = None  # global shared model\n",
    "\n",
    "\n",
    "class NeuroBrain:\n",
    "    def __init__(self, media_type='movies'):\n",
    "        global _shared_model\n",
    "\n",
    "        self.media_type = media_type\n",
    "        self.data_path = f'data/{media_type}.csv'\n",
    "        self.index_path = f'data/{media_type}_index.bin'\n",
    "        self.model_name = 'all-MiniLM-L6-v2'\n",
    "        self.df = pd.DataFrame()\n",
    "\n",
    "        print(f\"Initializing NeuroBrain for {self.media_type.upper()}...\")\n",
    "\n",
    "        # 1. Load data\n",
    "        if os.path.exists(self.data_path):\n",
    "            try:\n",
    "                self.df = pd.read_csv(self.data_path)\n",
    "\n",
    "                # ID cleanup\n",
    "                if 'id' in self.df.columns:\n",
    "                    self.df['id'] = self.df['id'].astype(str)\n",
    "                elif 'movie_id' in self.df.columns:\n",
    "                    self.df['id'] = self.df['movie_id'].astype(str)\n",
    "                elif 'appid' in self.df.columns:\n",
    "                    self.df['id'] = self.df['appid'].astype(str)\n",
    "                else:\n",
    "                    self.df['id'] = self.df.index.astype(str)\n",
    "\n",
    "                # Year cleanup\n",
    "                if 'release_date' in self.df.columns:\n",
    "                    self.df['release_date'] = pd.to_datetime(self.df['release_date'], errors='coerce')\n",
    "                    self.df['year'] = self.df['release_date'].dt.year.fillna(0).astype(int)\n",
    "                elif 'year' in self.df.columns:\n",
    "                    self.df['year'] = self.df['year'].fillna(0).astype(int)\n",
    "                else:\n",
    "                    self.df['year'] = 0\n",
    "\n",
    "                # Ensure required columns exist\n",
    "                for col in ['vote_average', 'title', 'tags']:\n",
    "                    if col not in self.df.columns:\n",
    "                        self.df[col] = \"\"\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading CSV: {e}\")\n",
    "                return\n",
    "        else:\n",
    "            print(f\"Data file missing: {self.data_path}\")\n",
    "            return\n",
    "\n",
    "        # 2. Load / share SentenceTransformer model\n",
    "        if _shared_model is None:\n",
    "            print(\"Loading SentenceTransformer model (once)...\")\n",
    "            _shared_model = SentenceTransformer(self.model_name)\n",
    "        self.model = _shared_model\n",
    "\n",
    "        # 3. Load or build FAISS index\n",
    "        if not self.df.empty:\n",
    "            if os.path.exists(self.index_path):\n",
    "                print(f\"Loading FAISS index from {self.index_path}...\")\n",
    "                self.index = faiss.read_index(self.index_path)\n",
    "            else:\n",
    "                print(\"No index found. Building new index...\")\n",
    "                self.build_index()\n",
    "\n",
    "        print(f\"{self.media_type.upper()} brain ready.\")\n",
    "\n",
    "    def build_index(self):\n",
    "        if self.df.empty:\n",
    "            return\n",
    "        text_data = (self.df['title'].astype(str) + \" \" + self.df['tags'].astype(str)).tolist()\n",
    "        embeddings = self.model.encode(text_data, show_progress_bar=True)\n",
    "        embeddings = np.array(embeddings).astype('float32')\n",
    "        dimension = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatL2(dimension)\n",
    "        self.index.add(embeddings)\n",
    "        faiss.write_index(self.index, self.index_path)\n",
    "        print(\"Index built and saved.\")\n",
    "\n",
    "    def search(self, query, top_k=20):\n",
    "        if self.df.empty or not hasattr(self, 'index'):\n",
    "            return []\n",
    "        query_vector = self.model.encode([query]).astype('float32')\n",
    "        fetch_k = min(top_k * 5, len(self.df))\n",
    "        distances, indices = self.index.search(query_vector, fetch_k)\n",
    "\n",
    "        results = []\n",
    "        for idx in indices[0]:\n",
    "            if idx == -1:\n",
    "                continue\n",
    "            item = self.df.iloc[idx]\n",
    "            results.append(self._format_item(item))\n",
    "            if len(results) >= top_k:\n",
    "                break\n",
    "        return results\n",
    "\n",
    "    def get_random(self, top_k=10):\n",
    "        if self.df.empty:\n",
    "            return []\n",
    "        n = min(top_k, len(self.df))\n",
    "        samples = self.df.sample(n=n).to_dict(orient='records')\n",
    "        return [self._format_item(item) for item in samples]\n",
    "\n",
    "    def _format_item(self, item):\n",
    "        \"\"\"Return a compact dict without poster/overview.\"\"\"\n",
    "        obj = {\n",
    "            'id': str(item.get('id', '')),\n",
    "            'title': str(item.get('title', 'Unknown')),\n",
    "            'year': int(item.get('year', 0)),\n",
    "            'vote_average': float(item.get('vote_average', 0.0)),\n",
    "            'type': self.media_type\n",
    "        }\n",
    "        if 'developer' in item:\n",
    "            obj['developer'] = str(item['developer'])\n",
    "        if 'publisher' in item:\n",
    "            obj['publisher'] = str(item['publisher'])\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8ca85",
   "metadata": {},
   "source": [
    "### Recommendation Engine Initialization\n",
    "\n",
    "We instantiate separate `NeuroBrain` engines for movies and games, each loading its own dataset, embeddings index, and shared transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d724f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing NeuroBrain for MOVIES...\n",
      "Loading FAISS index from data/movies_index.bin...\n",
      "MOVIES brain ready.\n",
      "Initializing NeuroBrain for GAMES...\n",
      "Loading FAISS index from data/games_index.bin...\n",
      "GAMES brain ready.\n"
     ]
    }
   ],
   "source": [
    "# Initialize engines for both media types\n",
    "\n",
    "movies_engine = NeuroBrain('movies')\n",
    "games_engine = NeuroBrain('games')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a5e253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to display recommendations as a DataFrame\n",
    "\n",
    "def show_recommendations(engine, query, top_k=5):\n",
    "    results = engine.search(query, top_k=top_k)\n",
    "    if not results:\n",
    "        return \"No results.\"\n",
    "    return pd.DataFrame(results)[['title', 'year', 'vote_average']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65d9a75",
   "metadata": {},
   "source": [
    "### Example Recommendations\n",
    "\n",
    "The following cells show example recommendations for different natural-language queries over movies and games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "485cf7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Star Trek Into Darkness</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red Planet</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Serenity</td>\n",
       "      <td>2005</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Day the Earth Stood Still</td>\n",
       "      <td>2008</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  year  vote_average\n",
       "0        Star Trek Into Darkness  2013           7.4\n",
       "1                     Red Planet  2000           5.4\n",
       "2                       Serenity  2005           7.4\n",
       "3  The Day the Earth Stood Still  2008           5.2\n",
       "4                   Interstellar  2014           8.1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1: movie query\n",
    "\n",
    "show_recommendations(movies_engine, \"emotional sci-fi space drama\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "356038ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>May</td>\n",
       "      <td>2002</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regression</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dark City</td>\n",
       "      <td>1998</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dressed to Kill</td>\n",
       "      <td>1980</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Dark Hours</td>\n",
       "      <td>2005</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title  year  vote_average\n",
       "0              May  2002           6.3\n",
       "1       Regression  2015           5.3\n",
       "2        Dark City  1998           7.2\n",
       "3  Dressed to Kill  1980           6.8\n",
       "4   The Dark Hours  2005           5.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2: another movie query\n",
    "\n",
    "show_recommendations(movies_engine, \"dark psychological thriller\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76ce70fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Book of Legends</td>\n",
       "      <td>2014</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La Tale - Evolved</td>\n",
       "      <td>2017</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UnReal World</td>\n",
       "      <td>2016</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Memory of Eldurim</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thea 2: The Shattering</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title  year  vote_average\n",
       "0     The Book of Legends  2014           7.1\n",
       "1       La Tale - Evolved  2017           5.2\n",
       "2            UnReal World  2016           9.6\n",
       "3   The Memory of Eldurim  2014           4.8\n",
       "4  Thea 2: The Shattering  2018           8.2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1: game query\n",
    "\n",
    "show_recommendations(games_engine, \"open world RPG with rich story\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60c9e1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rogue Shooter: The FPS Roguelike</td>\n",
       "      <td>2014</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ballistic Overkill</td>\n",
       "      <td>2017</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Art of Fight | 4vs4 Fast-Paced FPS</td>\n",
       "      <td>2017</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mad Bullets</td>\n",
       "      <td>2016</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shot Shot Tactic</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title  year  vote_average\n",
       "0        Rogue Shooter: The FPS Roguelike  2014           7.5\n",
       "1                      Ballistic Overkill  2017           7.6\n",
       "2  The Art of Fight | 4vs4 Fast-Paced FPS  2017           7.0\n",
       "3                             Mad Bullets  2016           9.2\n",
       "4                        Shot Shot Tactic  2016           4.3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2: another game query\n",
    "\n",
    "show_recommendations(games_engine, \"fast-paced competitive shooter\", top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd7ae25",
   "metadata": {},
   "source": [
    "## Evaluation & Analysis\n",
    "\n",
    "- **Metrics used (qualitative):** Due to the lack of user‚Äëlevel interaction data, the system is evaluated qualitatively by manually inspecting the top‚Äëk recommendations for different natural-language queries and checking genre, theme, and mood consistency. This is a common approach for early-stage content-based recommenders when click or rating logs are not available.\n",
    "\n",
    "- **Sample outputs:** The previous cells show sample recommendations for movie queries such as ‚Äúemotional sci‚Äëfi space drama‚Äù and game queries such as ‚Äúopen world RPG with rich story‚Äù. The returned items are generally consistent in genre (sci‚Äëfi, RPG) and tone, indicating that the semantic embeddings + FAISS pipeline is capturing high-level content similarity. \n",
    "\n",
    "- **Performance analysis and limitations:** While the recommendations are thematically coherent, the system does not optimize any explicit ranking metric such as Precision@k or NDCG, and it cannot personalize results to individual users because only item content is modeled. It also inherits popularity and representation biases from the TMDB and Steam datasets, and items with sparse or poor text metadata may receive lower-quality recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1a1b97",
   "metadata": {},
   "source": [
    "## Ethical Considerations & Responsible AI\n",
    "\n",
    "- **Bias and fairness:** The recommender inherits popularity and representation biases from TMDB and Steam, so already popular genres, studios, and AAA titles are more likely to be suggested than niche or indie content. Popularity bias is a well‚Äëknown ethical issue in recommender systems.\n",
    "\n",
    "- **Dataset limitations:** Both datasets are historically bounded: the TMDB 5000 movies metadata mostly covers titles released before 2017‚Äì2018, and the Steam games dataset only includes games available on Steam before around 2019. This means recent releases and games from other platforms (PlayStation, Xbox, Switch, mobile, etc.) are completely absent, limiting coverage and making the system unsuitable for ‚Äúlatest releases‚Äù discovery.\n",
    "\n",
    "- **Responsible use:** The system is designed for entertainment discovery only and should not be used for high‚Äëstakes or sensitive decisions. Any real‚Äëworld deployment should clearly communicate these limitations, avoid over‚Äëpersonalization that could create filter bubbles, and continuously monitor for biased or harmful recommendation patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa183dd",
   "metadata": {},
   "source": [
    "## 7. Conclusion & Future Scope\n",
    "\n",
    "- **Summary of results:** The project demonstrates a content‚Äëbased recommendation engine that uses transformer embeddings and FAISS to retrieve semantically similar movies and games from TMDB and Steam datasets, producing thematically coherent recommendations for natural‚Äëlanguage queries.\n",
    "\n",
    "- **Possible improvements and extensions:** Future work could add user interaction data for personalization, adopt more recent and broader datasets that include post‚Äë2019 titles and non‚ÄëSteam platforms, experiment with larger or domain‚Äëspecific embedding models, and introduce quantitative ranking metrics (e.g., Precision@k, NDCG) and A/B testing for more rigorous evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
